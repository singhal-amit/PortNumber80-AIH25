# ğŸ“„ Challenge 1a: PDF Processing Solution

## ğŸ Overview
This repository contains the solution for **Challenge 1a** of the **Adobe India Hackathon 2025**. The objective is to implement a containerized solution that processes PDF documents and extracts structured data into **JSON** format, while adhering to **performance**, **resource**, and **offline** constraints.

<details>
<summary><strong>ğŸ“‘ Table of Contents</strong></summary>

- [ğŸ Overview](#-overview)  
- [ğŸ§  Tech Stack](#-tech-stack)
- [âš™ï¸ Installation & Running](#ï¸-installation--running)
- [ğŸ§ª Testing the Solution](#-testing-the-solution)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ“Œ Implementation Details](#-implementation)
- [ğŸ“‹ Validation Checklist](#-validation-checklist)

</details>

## Solution_1a Demo

[demo.mp4](https://github.com/user-attachments/assets/ce1a6c98-7159-4197-acea-54de93998d99)

---

## ğŸ§  Tech Stack

| ğŸ”§ Component       | ğŸ’» Technology Used                                      | ğŸ” Purpose                                |
|-------------------|---------------------------------------------------------|-------------------------------------------|
| ğŸ **Language**    | ![Python](https://img.shields.io/badge/Python-3.11-blue) | Core development language                  |
| ğŸ“„ **PDF Parsing** | `PyMuPDF`, `pdfplumber`                                | Extract text, layout, and metadata         |
| ğŸ¤– **ML Framework**| `Transformers` (HuggingFace)                           | Language modeling and heading detection    |
| ğŸ§  **Model**       | `BERT-tiny` (local)                                    | Lightweight model for classification       |
| ğŸ³ **Container**   | `Docker`                                               | Containerization of the solution           |
| ğŸ§ª **Testing**     | `pytest`                                               | Test suite for validation and regression   |
| ğŸ“¦ **Utilities**   | `tqdm`, `scikit-learn`, `argparse`                     | Progress bar, clustering, CLI parsing      |

---

## ğŸ§  Technical Approach

### **Key Steps**

---

**ğŸ“„ PDF Parsing**

* Use **PyMuPDF (`fitz`)** to extract text blocks page-by-page.
* Identify text spans, font sizes, positions, and styling (boldness).

---

**ğŸ·ï¸ Title Extraction**

* Heuristic: Select the **largest font size text** on the first page.
* Combine multiple spans if needed to form a clean title.

---

**ğŸ“ Heading Detection**

* Combine **heuristics** (larger font size than body text, bold style, header region) with **semantic similarity** checks.
* Use a **local BERT-tiny** model to verify whether a text line matches typical heading phrases.
* Ignore repetitive page headers/footers and unrelated fields (e.g., form labels).

---

**ğŸ”¢ Level Assignment**

* Infer heading level (**H1**, **H2**, **H3**) based on **relative font sizes** found on each page.
* Fallback to simple heuristics to handle inconsistent font usage.

---

**ğŸ“‘ Output Generation**

* Save the extracted **Title** and **headings** in the required **JSON format**:

  ```json
  {
    "title": "Document Title",
    "outline": [
      {"level": "H1", "text": "Introduction", "page": 1},
      {"level": "H2", "text": "Background", "page": 2}
    ]
  }
  ```
* Output **one JSON** per input PDF.

---

**ğŸ³ Containerization**

* All code runs **offline inside a Docker container**.
* Uses `FROM --platform=linux/amd64` to ensure AMD64 CPU compatibility.
* `requirements.txt` installs only necessary local dependencies.
* The **local snapshot** of **`prajjwal1/bert-tiny`** is bundled to avoid internet calls at runtime.

---

## âš™ï¸ Installation & Running

```bash
# Clone the repository
git clone https://github.com/singhal-amit/PortNumber80-AIH25.git
cd PortNumber80-AIH25

# Build and start the container (Docker Compose)
docker compose build
docker compose up
````

---

## ğŸ§ª Testing the Solution

### ğŸ Debug Individual PDFs

```bash
# Navigate into Solution_1a
cd Solution_1a

# Debug PDF layout and structure
python debug/debug_pdf.py

# Debug title and heading extraction logic
python debug/debug_title.py
```

### âœ… Run Test Suite

```bash
# Run test suite from Solution_1a
python tests/test_solution.py
```

---

## ğŸ“ Project Structure

```
ğŸ“ Solution_1a/
â”œâ”€â”€ ğŸ“„ Dockerfile                   # Container config
â”œâ”€â”€ ğŸ“„ process_pdfs.py              # Main script for processing PDFs
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ ğŸ“ debug/                       # Debug scripts
â”‚   â”œâ”€â”€ ğŸ debug_pdf.py
â”‚   â””â”€â”€ ğŸ debug_title.py
â”‚
â”œâ”€â”€ ğŸ“ local_model/                 # Offline transformer model (BERT-tiny)
â”‚   â””â”€â”€ ğŸ“ models--prajjwal1--bert-tiny/
â”‚
â”œâ”€â”€ ğŸ“ pdf_outliner/                # PDF outline extraction logic
â”‚   â””â”€â”€ ğŸ“„ extractor.py
â”‚
â”œâ”€â”€ ğŸ“ sample_dataset/              # Dataset for evaluation
â”‚   â”œâ”€â”€ ğŸ“ expected_outputs/        # Provided expected JSON
â”‚   â”œâ”€â”€ ğŸ“ outputs/                 # Our generated output
â”‚   â”œâ”€â”€ ğŸ“ pdfs/                    # Input PDF files
â”‚   â””â”€â”€ ğŸ“ schema/                  # JSON schema
â”‚       â””â”€â”€ ğŸ“„ output_schema.json
â”‚
â””â”€â”€ ğŸ“ tests/
    â””â”€â”€ ğŸ“„ test_solution.py         # Unit tests
```

---

## ğŸ“Œ Implementation

### Solution Overview

The provided `process_pdfs.py` script is a starting point that:

* Scans the input directory for PDF files
* Uses rule-based + ML techniques to extract structure
* Generates `filename.json` for every `filename.pdf`

### Performance Guidelines

* âš™ï¸ Efficient use of **CPU (8 cores)** and **RAM (â‰¤16 GB)**
* â±ï¸ Processing should complete within **10 seconds** for 50-page documents
* ğŸŒ Fully **offline** and **network-isolated**
* ğŸ§  ML model is **< 200MB**, locally available

### Testing Guidelines

* Covers **simple**, **complex**, and **large** PDFs
* Validates format against schema
* Includes **unit tests** and **debug utilities**

---

## ğŸ“‹ Validation Checklist

### âœ… Core Requirements

* [x] Process all PDFs in input directory
* [x] Generate structured JSON output for each PDF
* [x] Match output format with schema (`output_schema.json`)
* [x] Entirely offline: No internet access required
* [x] All dependencies and models are open source

### âœ… Performance & Constraints

* [x] Complete 50-page PDF processing < 10s
* [x] â‰¤ 16GB RAM usage
* [x] ML model â‰¤ 200MB
* [x] Efficient CPU usage (8 cores)
* [x] AMD64 compatibility

### âœ… Docker Requirements

* [x] Functional `Dockerfile`
* [x] Works with `--platform linux/amd64`
* [x] Read-only input mount
* [x] Writable output mount
* [x] `--network none` enforced

### âœ… Code Quality & Testing

* [x] Well-structured code and modular design
* [x] All dependencies in `requirements.txt`
* [x] Unit tests implemented and passing
* [x] Debug scripts available
* [x] Meaningful error handling and logging

---

## ğŸ‘¥ **Team PortNumber80**

| GitHub                                                                                                                              | Name             | Role                                              |
| ----------------------------------------------------------------------------------------------------------------------------------- | ---------------- | ------------------------------------------------- |
| <a href="https://github.com/gkjha2772"><img src="https://avatars.githubusercontent.com/u/151064648?v=4&s=100" width="50"/></a>      | Gautam Kumar Jha | â€¢ Built Solution 1b                               |
| <a href="https://github.com/amit712singhal"><img src="https://avatars.githubusercontent.com/u/123376849?v=4&s=100" width="50"/></a> | Amit Singhal     | â€¢ Built Solution 1a                               |
